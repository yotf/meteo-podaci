{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import re\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000EA5_station_data.xlsx\n",
      "00000EA5\n",
      "2010-04-20 00:00:00 2013-03-29 00:00:00\n",
      "2013-03-29 00:00:00 2019-01-27 23:16:12.767157\n",
      "00000E94_station_data.xlsx\n",
      "00000E94\n",
      "2010-04-16 00:00:00 2019-01-27 23:16:21.356031\n",
      "00000E9A_station_data.xls\n",
      "00000E9A\n",
      "2013-08-02 00:00:00 2018-11-19 00:00:00\n"
     ]
    }
   ],
   "source": [
    "###Citanje tabela sa PIS sajta\n",
    "### Tabele su prethodno prebacene u xls format\n",
    "###\n",
    "#*Vadjenje pouzdanih periods\n",
    "#*Nalazenje i zabalezavanje rupa u temperaturama i u datumima (satima)\n",
    "\n",
    "\n",
    "folder_podataka = \"./PISpodaci\"\n",
    "folder_rezultata = \"./results\"\n",
    "pregled = pd.read_excel(\"./samoPouzdaniPodaciTabela.xlsx\", converters= {'kraj': pd.to_datetime, 'pocetak': pd.to_datetime})\n",
    "preslikavanje_opstina = {\"Novi Sad\": \"NS\", \"Ruma\":\"RU\",\"Sombor\":\"SO\"}\n",
    "preslikavanje_lokacija = {\"Cenej\": \"CE\" ,\"Novi Slankamen\":\"NS\",\"Ridjica\":\"RI\",\"Sremski Karlovci\":\"SK\"}\n",
    "z=None\n",
    "#za svaku PIS tabelu, cemo napraviti korespondirajucu PIS tabelu, sa pouzdanim podacima + vrsta i mesto\n",
    "# VAZNO !! Moraju biti prebaceni u xls format posle skidanja sa PIS sajta. To se moze uraditi otvaranjem u Excelu i cuvsanju u xls formatu\n",
    "for fname in os.listdir(folder_podataka):\n",
    "    print (fname)\n",
    "    #IZVLACENJE AMS naziva iz imena fajla !\n",
    "    ams =fname.split('_')[0] ## REFACTOR - ovo mora da bude regex. \n",
    "    print(ams)\n",
    "    assert(re.match(\"0+[0-9A-F]+\",ams)) # REFACTOR - napravi bolji regex, more robust\n",
    "    #IZVLACENJE PODATAKA IZ PREGLED TABELE\n",
    "    record_for_ams = pregled[pregled.ams==ams] #za ovu ams samo trzimo records\n",
    "    #ako nije oznacen kraj - popunimo ga sa trenutnim datumom, posto to znaci da je jos uvek tamo\n",
    "    record_for_ams.kraj = record_for_ams.kraj.fillna(pd.Timestamp.today())#REFACTOR TODO!! - popuni ih sa poslednjom skinutom vrednoscu za taj AMS (to je preciznije)\n",
    "    #UCITAVANJE TABELE\n",
    "    PIStabela=pd.read_excel(os.path.join(folder_podataka,fname),header=[0,1])\n",
    "    PIStabela = PIStabela.sort_index()\n",
    "    #flattening the header\n",
    "    #SREDJIVANJE TABELE!!\n",
    "    PIStabela.columns = [' '.join(col).strip() for col in PIStabela.columns.values]\n",
    "    #samo uzimamo temperature, tj prve tri kolone, za ovu svrhu \n",
    "    PIStabela = PIStabela.iloc[:,0:3]\n",
    "    assert(\"Temperature\" in col for col in PIStabela.columns)\n",
    "#z = pd.concat(z.values(),axis=0)\n",
    "    assert(len(PIStabela.columns)==3)\n",
    "    #prvo cemo ih iseci po periodima, i onda cemo ih spojiti u jednu tabelu !!\n",
    "    tabele_za_jedan_ams = []\n",
    "    #pravimo i tabele sa nedostajucim vrednostima\n",
    "    missing_periods_za_jedan_ams = []\n",
    "    missing_data_za_ams = []\n",
    "    #idemo kroz PREGLED tabelu i za svaku stavku odvojim deo PIS tabele, koja je pouzdana\n",
    "    for index,row in record_for_ams.iterrows():\n",
    "        assert(row.pocetak< row.kraj)\n",
    "        print (row.pocetak,row.kraj)\n",
    "        #izuzimamo dan postavljanja, posto ne znamo kad je postavljenja\n",
    "        izuzet_dan_postavljanja = (row.pocetak+pd.offsets.DateOffset(days=1)) \n",
    "        #uzimamo samo deo za koji znamo da je pouzdan (tj. bio na lokaciji bez pomeranja)\n",
    "        novi = PIStabela.loc[izuzet_dan_postavljanja:row.kraj].copy() \n",
    "        #popunjavamo ostale podatke, posto znamo da su bili sigurno na jednoj lokaciji u jednoj sorti za taj period\n",
    "        novi[\"opstina\"] = row.opstina #popunjavamo podatke, koje sad znamo za sigurno\n",
    "        novi[\"mesto\"] = row.mesto\n",
    "        novi[\"usev\"] = row.usev\n",
    "        tabele_za_jedan_ams.append(novi) #jos uvek smo kod istog AMS-a, i sve sto nadjemo cemo nakaciti\n",
    "        missing_temperatures = novi[novi.isnull().any(axis=1)] # kolone koje imaju nedostajuce vrednosti, tj. temperature u ovom slucaju\n",
    "        #cuvamo ovaj deo podataka (mozda je suvisno !)\n",
    "        novi.to_csv(os.path.join(folder_rezultata,\"%s_%s_%s_%s_%s.csv\"%(ams,preslikavanje_opstina[row.opstina],preslikavanje_lokacija[row.mesto],row.usev,row.pocetak)))    \n",
    "        #Trazimo nedostajuce datume \n",
    "        idx_ref = pd.DatetimeIndex(start=novi.index[0], end=novi.index[-1], freq=\"h\")\n",
    "        gaps = idx_ref[~idx_ref.isin(novi.index)]\n",
    "        missing = pd.DataFrame(index=gaps)\n",
    "        missing[\"opstina\"]= row.opstina\n",
    "        missing[\"mesto\"] = row.mesto\n",
    "        missing[\"usev\"] = row.usev\n",
    "        #zapisujemo nedostajuce datume za jedan period - mozda suvisno !\n",
    "        missing.to_csv(os.path.join(folder_rezultata,\"missing_periods_%s_%s\" %(ams+row.opstina+row.mesto +row.usev,row.pocetak)))\n",
    "        #sve missinge sa odredjen ams cuvamo u jednoj tabeli - mozemo ih kasnije po lokaciji ako treba\n",
    "        missing_periods_za_jedan_ams.append(missing)\n",
    "        missing_data_za_ams.append(missing_temperatures)\n",
    "    frejmovi_za_ams = pd.concat(tabele_za_jedan_ams)\n",
    "    \n",
    "    #svi valjani podaci za jedan ams\n",
    "    frejmovi_za_ams.to_csv(os.path.join(folder_rezultata,\"%s_pouzdaniPeriodi_biljneVrste_lokacije.csv\" %(ams)))\n",
    "    missing_periods = pd.concat(missing_periods_za_jedan_ams)\n",
    "    missing_periods.to_csv(os.path.join(folder_rezultata,\"%s_missing_periods.csv\" %ams))\n",
    "    missing_data = pd.concat(missing_data_za_ams)\n",
    "    missing_data.to_csv(os.path.join(folder_rezultata,\"%s_missing_data.csv\" %ams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def izracunaj_CHU(podaci):\n",
    "\n",
    "    zbir = 0\n",
    "    end_of_chilling_index = None\n",
    "    end_of_chilling_date = None\n",
    "    chilling_units_max = 1800\n",
    "    for index, row in podaci.iterrows(): \n",
    "        if row.Tavg <= 1.4:\n",
    "            zbir+=0\n",
    "        elif row.Tavg <=2.4:\n",
    "            zbir+=0.5\n",
    "        elif row.Tavg <= 9.1:\n",
    "            zbir+=1\n",
    "        elif row.Tavg <=12.4:\n",
    "            zbir+=0.5\n",
    "        elif row.Tavg <=15.9:\n",
    "            zbir+=0\n",
    "        elif row.Tavg <=18.0:\n",
    "            zbir+=-0.5\n",
    "        else:\n",
    "            zbir+=-1\n",
    "    return zbir\n",
    "        \n",
    "def izracunaj_HU(podaci):\n",
    "    \n",
    "    Tu = 25 # optimum temperature\n",
    "    Tc = 36 # critical temperature\n",
    "    Tb = 4 #base temperature\n",
    "    F = 1 # plant stress factor, 1 where no particular stress\n",
    "    GDH = 0\n",
    "    for i, row in podaci.iterrows():\n",
    "        if (row.Tavg >=Tb) and (row.Tavg < Tu):\n",
    "            z =  F*((Tu-Tb)/2)*(1+ math.cos(math.pi + math.pi*((row.Tavg -Tb)/(Tu-Tb))))\n",
    "            GDH+=z  \n",
    "        elif (row.Tavg >=Tu) and (row.Tavg<=Tc):\n",
    "            z= F*(Tu-Tb)*(1+ math.cos(math.pi/2 + (math.pi/2)*((row.Tavg -Tu)/(Tc-Tu))))\n",
    "            GDH+=z\n",
    "        else:\n",
    "            GDH+=0\n",
    "            \n",
    "    return GDH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lokalitet: NS_CE\n",
      "sorta: ZD\n",
      "chilling start: 2017-11-01 00:00:00 chilling end: 2018-02-06 00:00:00\n",
      "CHU: 1320.5\n",
      "HU: 6566.825783430308\n",
      "sorta: AJ\n",
      "chilling start: 2016-11-01 00:00:00 chilling end: 2017-02-28 00:00:00\n",
      "CHU: 914.5\n",
      "HU: 5241.589087538984\n",
      "sorta: ZD\n",
      "chilling start: 2016-11-01 00:00:00 chilling end: 2017-03-08 00:00:00\n",
      "CHU: 1005.0\n",
      "HU: 4248.7373879070565\n",
      "sorta: ZD\n",
      "chilling start: 2013-11-01 00:00:00 chilling end: 2014-03-04 00:00:00\n",
      "CHU: 1396.5\n",
      "HU: 3899.0492094847177\n",
      "sorta: AJ\n",
      "chilling start: 2017-11-01 00:00:00 chilling end: 2018-01-30 00:00:00\n",
      "CHU: 1238.0\n",
      "HU: 6888.582049451345\n",
      "sorta: AJ\n",
      "chilling start: 2013-11-01 00:00:00 chilling end: 2014-02-24 00:00:00\n",
      "CHU: 1259.0\n",
      "HU: 4303.470742293736\n",
      "sorta: AJ\n",
      "chilling start: 2015-11-01 00:00:00 chilling end: 2016-01-13 00:00:00\n",
      "CHU: 848.0\n",
      "HU: 3271.125033056013\n",
      "sorta: AJ\n",
      "chilling start: 2014-11-01 00:00:00 chilling end: 2015-02-24 00:00:00\n",
      "CHU: 1470.5\n",
      "HU: 5480.77181485618\n",
      "sorta: ZD\n",
      "chilling start: 2015-11-01 00:00:00 chilling end: 2016-02-08 00:00:00\n",
      "CHU: 1109.5\n",
      "HU: 5602.221917175587\n",
      "sorta: ZD\n",
      "chilling start: 2014-11-01 00:00:00 chilling end: 2015-03-11 00:00:00\n",
      "CHU: 1747.0\n",
      "HU: 5060.462229506192\n",
      "  sorta lokalitet   CHU    HU chilling start dormancy end dormancy end BBCH  \\\n",
      "0    ZD     NS_CE  1320  6566     2017-11-01   2018-02-06                 1   \n",
      "1    AJ     NS_CE   914  5241     2016-11-01   2017-02-28                 1   \n",
      "2    ZD     NS_CE  1005  4248     2016-11-01   2017-03-08                 3   \n",
      "3    ZD     NS_CE  1396  3899     2013-11-01   2014-03-04                 3   \n",
      "4    AJ     NS_CE  1238  6888     2017-11-01   2018-01-30                 1   \n",
      "5    AJ     NS_CE  1259  4303     2013-11-01   2014-02-24                 1   \n",
      "6    AJ     NS_CE   848  3271     2015-11-01   2016-01-13                 1   \n",
      "7    AJ     NS_CE  1470  5480     2014-11-01   2015-02-24                 1   \n",
      "8    ZD     NS_CE  1109  5602     2015-11-01   2016-02-08                 1   \n",
      "9    ZD     NS_CE  1747  5060     2014-11-01   2015-03-11                 1   \n",
      "\n",
      "  flowering start flowering start BBCH  \n",
      "0      2018-04-18                   65  \n",
      "1      2017-04-05                   65  \n",
      "2      2017-04-05                   65  \n",
      "3      2014-04-02                   60  \n",
      "4      2018-04-18                   65  \n",
      "5      2014-04-02                   65  \n",
      "6      2016-03-29                   65  \n",
      "7      2015-04-22                   65  \n",
      "8      2016-04-08                   61  \n",
      "9      2015-04-22                   61  \n"
     ]
    }
   ],
   "source": [
    "mesta = [\"RU_IK\",\"SM_MA\",\"ZR_SU\",\"NS_CE\",\"RU_NS\"]\n",
    "mesta = [\"NS_CE\"]\n",
    "sorte = [\"ZD\",\"AJ\"]\n",
    "\n",
    "rezultat = pd.DataFrame(columns = [\"sorta\",\"lokalitet\",\"CHU\",\"HU\",\"chilling start\",\"dormancy end\",\"dormancy end BBCH\",\"flowering start\",\"flowering start BBCH\"])\n",
    "\n",
    "#za sve podatke koje imamo popunjene/pouzdane\n",
    "#cemo citati ove podatke fenologije\n",
    "\n",
    "folder_fenologija = \"./fenologija\"\n",
    "folder_podataka = \"./results/popunjenirezultati\"\n",
    "\n",
    "for fname_podaci in os.listdir(folder_podataka): # za svaki set podataka\n",
    "    lokalitet = fname_podaci[:5] #NS_CE npr\n",
    "    assert (lokalitet in mesta) #provera \n",
    "    print (\"lokalitet: %s\" %lokalitet)\n",
    "     #ucitavamo podatke\n",
    "    podaci = pd.read_csv(os.path.join(folder_podataka,fname_podaci),index_col=0)\n",
    "    #stavljamo da index bude datum, vazno je da je dayfirst=True, posto su tako sacuvani izgleda\n",
    "    podaci.index = pd.to_datetime(podaci.index,dayfirst=True)\n",
    "    \n",
    "    #uzimamo sve podatke fenologije za odabrani lokalitet (tj. onaj koji je na redu)\n",
    "    gen = (fname for fname in os.listdir(folder_fenologija) if lokalitet in fname)\n",
    "    #za svaku fenolosku tabelu za odabran lokalitet\n",
    "    for fname_fenologija in gen:\n",
    "        #uzimamo godinu i sortu iz naziva fajla \n",
    "        year = int(fname_fenologija.split(\"_\")[3].split(\".\")[0])\n",
    "        sorta = fname_fenologija.split(\"_\")[-2]\n",
    "        print (\"sorta: %s\" %sorta)\n",
    "        #pocinjemo racunanje od Novembra prosle godine\n",
    "        chilling_start = pd.Timestamp(year=year-1, month=11, day=1, hour=0)\n",
    "        #ucitavanje i sredjivanje tabele (sortiranje po datumima)\n",
    "        fenologija = pd.read_excel(os.path.join(folder_fenologija,fname_fenologija))\n",
    "        fenologija.Date = pd.to_datetime(fenologija.Date,yearfirst=True)\n",
    "        fenologija = fenologija.set_index(fenologija.Date).drop(\"Date\",1).sort_index()\n",
    "        #kraj dormancije je prvi red u tabeli za koji je BBCH>=1\n",
    "        dormancy_end = fenologija[fenologija.BBCH>=1].iloc[0]\n",
    "        #cvetanje je prvi red u tabeli za koje je BBCH>=60\n",
    "        cvetanje = fenologija[fenologija.BBCH>=60].iloc[0]\n",
    "\n",
    "        dormancy_end_date = dormancy_end.name\n",
    "        cvetanje_start_date = cvetanje.name\n",
    "        print(\"chilling start: %s chilling end: %s\" %(chilling_start,dormancy_end_date))\n",
    "        # podaci za racunanje CHU-a, od pocetka novembra do kraja dormancije\n",
    "        chilling_period_podaci = podaci.loc[chilling_start:dormancy_end_date]\n",
    "        CHU = izracunaj_CHU(chilling_period_podaci)\n",
    "        print (\"CHU: %s\" %CHU)\n",
    "        #podaci za racunanje HU-a, od kraja dormancije do pocetka cvetanja\n",
    "        cvetanje_podaci = podaci.loc[dormancy_end_date:cvetanje_start_date]\n",
    "        HU =izracunaj_HU(cvetanje_podaci)\n",
    "        print (\"HU: %s\" %HU)\n",
    "        #sve stavljamo u jednu veliku tabelu iz koje cemo kasnije izvlaciiti lokalitet i sorte\n",
    "        rezultat = rezultat.append({\"sorta\":sorta,\"lokalitet\":lokalitet,\"CHU\":int(CHU),\"HU\":int(HU),\"chilling start\":chilling_start,\"dormancy end\": dormancy_end_date,\"dormancy end BBCH\":dormancy_end.BBCH,\"flowering start\":cvetanje_start_date,\"flowering start BBCH\": cvetanje.BBCH},ignore_index=True)\n",
    "        \n",
    "        \n",
    "print (rezultat)\n",
    "for sorta in sorte:\n",
    "    podaci_za_sortu = rezultat[rezultat.sorta==sorta]\n",
    "    podaci_za_sortu.to_csv(\"CHU_HU_%s.csv\" %sorta)\n",
    "    \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (modernpandas)",
   "language": "python",
   "name": "modernpandas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
